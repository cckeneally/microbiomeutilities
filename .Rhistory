}#end if "SAM"
result.allcorr<-ecol.ext.all(MM,Type,corcoef)
return(result.allcorr)
} #end cutoff.impact
###################################################################################
impct <- cutoff.impact(MM=tabs)
cutoff.impact<-function(MM=tabs, Type="ADS",corcoef="spearman",typem="dominant", details="y"){
require(MASS)
require(vegan)
#details=readline("\nDetails of the NMDS calculations? (y/n)...\t")
#calculation of the cut-off matrices, correlation coefficient, procrustes R value
CoCalc<-function(ODS,z,Type,corcoef,details=details){
res1<-matrix(NA,1,3)	#create a matrix to store mantel and procrustes data
colnames(res1)<-c("Sum","corrcoeff","R Procrustes")
#to remove all the lines in the matrix for which the sum of the line is 0
CLrow<-function(m) {
#to create a column of 0 in the last column
m=cbind(m,matrix(0,nrow(m),1))
m[,ncol(m)]=apply(m,1,sum)
#to keep only the lines without 0
mclean=subset(m,m[,ncol(m)]!=0)
mclean=mclean[,-ncol(mclean)]
return (mclean)
}
########################
CLcol<-function(m) {
#transpose the matrix and apply the same function as before
#then transpose back
m=t(m)
#to create a column of 0 in the last column
m=cbind(m,matrix(0,nrow(m),1))
m[,ncol(m)]=apply(m,1,sum)
#to keep only the lines without 0
mclean=subset(m,m[,ncol(m)]!=0)
mclean=mclean[,-ncol(mclean)]
mclean=t(mclean)
return (mclean)
}
#Application of a percentage cut-off to the original dataset to obtain abundant dataset
##all dataset-based cutoff
if(Type=="ADS"){
M<-rbind(ODS,apply(ODS,2,sum))	#add the column sum as a last row of the matrix M
if(typem=="dominant"){N<-M[,order(M[nrow(M),],decreasing=TRUE)]}	#order the columns of M by their decreasing sum
if(typem=="rare"){N<-M[,order(M[nrow(M),])]}  #order the columns of M by their increasing sum
Q<-N[1:(nrow(N)-1),]	#remove the last row (with the sum of the columns)
L<-ncol(Q)
K<-nrow(Q)
M1<-t(matrix(NA,L))	#create a vector to store sum of successive matrices
Q1<-matrix(NA,K,L)	#create a matrix to store new data
perc<-z*sum(ODS)
for (i in 1:L){	###for #1
M1[,i]<-sum(Q[,1:i])
if (M1[,i]<=perc) {Q1[,1:i]=Q[,1:i]}
row.names(Q1)=row.names(Q)
colnames(Q1)=colnames(Q)
if (M1[,i]>perc) {Q1[,1:i]==0}
}#end for #1
Q2<-Q1[,-which(apply(Q1,2,function(x)all(is.na(x))))]
Q2<-CLcol(CLrow(as.data.frame(Q2)))	#remove rows and columns whose sum=0
res1[1,1]<-sum(Q2)
} #end "ADS"
##sample-based cutoff
if(Type=="SAM"){
Q1<-ODS
if(typem=="dominant"){Q1[Q1<z]<-0}	# all species presents less than j times =0
if(typem=="rare"){Q1[Q1>z]<-0}	# all species presents more than j times =0
Q2<-CLcol(CLrow(Q1))	#remove rows and columns whose sum=0
res1[1,1]<-sum(Q2)
} #end "SAM"
if (res1[1,1]==0){res1[1,2:3]<-cbind(NA,NA)} # to avoid conflicts when comparing original dataset to NA
else {	if (length(Q2)<=nrow(ODS)){res1[1,2:3]<-cbind(NA,NA)} ###else #1
else { if (nrow(Q2)<nrow(ODS)) {res1[1,2:3]<-cbind(NA,NA)}
else { ###else #2
#####################################
#Correlation and Procrustes calculations
ODSdist<-vegdist(ODS,method="bray")	#distance matrix of the original dataset
Q2dist<-vegdist(Q2,distance="bray")	#distance matrix of the truncated dataset
ODSQ2cor<-cor.test(ODSdist,Q2dist,method=corcoef) #correlation between matrices
ODSdist2<-ODSdist
ODSdist2[ODSdist2==0]<-10e-20	#replace 0 by 10e-20 for original dataset
Q2dist2<-Q2dist
Q2dist2[Q2dist2==0]<-10e-20	#replace 0 by 10e-20 for truncated dataset
if(details=="y"){
ODSNMDS<-isoMDS(ODSdist2)	#NMDS for original dataset
Q2NMDS<-isoMDS(Q2dist2)		#NMDS for truncated dataset
}
else{if(details=="n"){     ###else #3
ODSNMDS<-isoMDS(ODSdist2,trace=0)	#NMDS for original dataset
Q2NMDS<-isoMDS(Q2dist2,trace=0)		#NMDS for truncated dataset
}}
ODSQ2procrustes<-protest(ODSNMDS,Q2NMDS) #procrustes
res1[1,2]<-cbind(ODSQ2cor$estimate)
res1[1,3]<-cbind(ODSQ2procrustes$t0)
} #end else #2
} #end else #1
}
#####################################
return(res1)
}#end function CoCalc
################################################################
#application of the function COP at different all dataset-based cutoffs
if(Type=="ADS"){
ecol.ext.all<-function(MM,Type,corcoef){
allcorr<-function(ODS,Type,corcoef){
ADS_perc<-c(0.01,seq(0.05,0.95,by=0.05),0.99)
table_taxa<-matrix(NA,length(ADS_perc),3)
row.names(table_taxa)<-ADS_perc
colnames(table_taxa)<-c("Sum","corrcoeff","R Procrustes")
for(i in 1:length(ADS_perc)){
table_taxa[((length(ADS_perc)+1)-i),]<-CoCalc(ODS,z=as.numeric(ADS_perc[i]),Type,corcoef)
}
#ROW<-row.names(table_taxa)
#table_taxa<-table_taxa[order(as.numeric(row.names(table_taxa)),decreasing=TRUE),]
#row.names(table_taxa)<-ROW
return(table_taxa)
} #end allcorr
list.ecol<-vector("list",length(MM))
names(list.ecol)<-names(MM)
for(j in 1:length(MM)){
list.ecol[[j]]<-allcorr(MM[[j]],Type,corcoef)
}
return(list.ecol)
} #end ecol.ext.all
}#end if "ADS"
#application of the function COP at different sample-based cutoffs
if(Type=="SAM"){
ecol.ext.all<-function(MM,Type,corcoef){
limSAMco=as.numeric(readline("\nIf SAM-based only, maximum cutoff value? (e.g. 208)...\t"))
allcorr<-function(ODS,Type,corcoef){
SAM_perc<-limSAMco*c(0.005,0.01,0.015,0.025,0.05,0.075,0.1,0.15,0.25,0.4,0.5,0.6,0.75,0.85,1)
table_taxa<-matrix(NA,length(SAM_perc),3)
row.names(table_taxa)<-round(SAM_perc,0)
colnames(table_taxa)<-c("Sum","corrcoeff","R Procrustes")
for(i in 1:length(SAM_perc)){
table_taxa[i,]<-CoCalc(ODS,z=as.numeric(SAM_perc[i]),Type,corcoef)
}
return(table_taxa)
} #end allcorr
list.ecol<-vector("list",length(MM))
names(list.ecol)<-names(MM)
for(j in 1:length(MM)){
list.ecol[[j]]<-allcorr(MM[[j]],Type,corcoef)
}
return(list.ecol)
} #end ecol.ext.all
}#end if "SAM"
result.allcorr<-ecol.ext.all(MM,Type,corcoef)
return(result.allcorr)
} #end cutoff.impact
###################################################################################
impct <- cutoff.impact(MM=tabs,details="y")
###################################################################################
impct <- cutoff.impact(MM=tabs,details="y")
cutoff.impact <- function(MM,Type="ADS",
corcoef="spearman",
typem="dominant",
details="y"){
require(MASS)
require(vegan)
#details=readline("\nDetails of the NMDS calculations? (y/n)...\t")
#calculation of the cut-off matrices, correlation coefficient, procrustes R value
CoCalc<-function(ODS,z,Type,corcoef){
res1<-matrix(NA,1,3)	#create a matrix to store mantel and procrustes data
colnames(res1)<-c("Sum","corrcoeff","R Procrustes")
#to remove all the lines in the matrix for which the sum of the line is 0
CLrow<-function(m) {
#to create a column of 0 in the last column
m=cbind(m,matrix(0,nrow(m),1))
m[,ncol(m)]=apply(m,1,sum)
#to keep only the lines without 0
mclean=subset(m,m[,ncol(m)]!=0)
mclean=mclean[,-ncol(mclean)]
return (mclean)
}
########################
CLcol<-function(m) {
#transpose the matrix and apply the same function as before
#then transpose back
m=t(m)
#to create a column of 0 in the last column
m=cbind(m,matrix(0,nrow(m),1))
m[,ncol(m)]=apply(m,1,sum)
#to keep only the lines without 0
mclean=subset(m,m[,ncol(m)]!=0)
mclean=mclean[,-ncol(mclean)]
mclean=t(mclean)
return (mclean)
}
#Application of a percentage cut-off to the original dataset to obtain abundant dataset
##all dataset-based cutoff
if(Type=="ADS"){
M<-rbind(ODS,apply(ODS,2,sum))	#add the column sum as a last row of the matrix M
if(typem=="dominant"){N<-M[,order(M[nrow(M),],decreasing=TRUE)]}	#order the columns of M by their decreasing sum
if(typem=="rare"){N<-M[,order(M[nrow(M),])]}  #order the columns of M by their increasing sum
Q<-N[1:(nrow(N)-1),]	#remove the last row (with the sum of the columns)
L<-ncol(Q)
K<-nrow(Q)
M1<-t(matrix(NA,L))	#create a vector to store sum of successive matrices
Q1<-matrix(NA,K,L)	#create a matrix to store new data
perc<-z*sum(ODS)
for (i in 1:L){	###for #1
M1[,i]<-sum(Q[,1:i])
if (M1[,i]<=perc) {Q1[,1:i]=Q[,1:i]}
row.names(Q1)=row.names(Q)
colnames(Q1)=colnames(Q)
if (M1[,i]>perc) {Q1[,1:i]==0}
}#end for #1
Q2<-Q1[,-which(apply(Q1,2,function(x)all(is.na(x))))]
Q2<-CLcol(CLrow(as.data.frame(Q2)))	#remove rows and columns whose sum=0
res1[1,1]<-sum(Q2)
} #end "ADS"
##sample-based cutoff
if(Type=="SAM"){
Q1<-ODS
if(typem=="dominant"){Q1[Q1<z]<-0}	# all species presents less than j times =0
if(typem=="rare"){Q1[Q1>z]<-0}	# all species presents more than j times =0
Q2<-CLcol(CLrow(Q1))	#remove rows and columns whose sum=0
res1[1,1]<-sum(Q2)
} #end "SAM"
if (res1[1,1]==0){res1[1,2:3]<-cbind(NA,NA)} # to avoid conflicts when comparing original dataset to NA
else {	if (length(Q2)<=nrow(ODS)){res1[1,2:3]<-cbind(NA,NA)} ###else #1
else { if (nrow(Q2)<nrow(ODS)) {res1[1,2:3]<-cbind(NA,NA)}
else { ###else #2
#####################################
#Correlation and Procrustes calculations
ODSdist<-vegdist(ODS,method="bray")	#distance matrix of the original dataset
Q2dist<-vegdist(Q2,distance="bray")	#distance matrix of the truncated dataset
ODSQ2cor<-cor.test(ODSdist,Q2dist,method=corcoef) #correlation between matrices
ODSdist2<-ODSdist
ODSdist2[ODSdist2==0]<-10e-20	#replace 0 by 10e-20 for original dataset
Q2dist2<-Q2dist
Q2dist2[Q2dist2==0]<-10e-20	#replace 0 by 10e-20 for truncated dataset
if(details=="y"){
ODSNMDS<-isoMDS(ODSdist2)	#NMDS for original dataset
Q2NMDS<-isoMDS(Q2dist2)		#NMDS for truncated dataset
}
else{if(details=="n"){     ###else #3
ODSNMDS<-isoMDS(ODSdist2,trace=0)	#NMDS for original dataset
Q2NMDS<-isoMDS(Q2dist2,trace=0)		#NMDS for truncated dataset
}}
ODSQ2procrustes<-protest(ODSNMDS,Q2NMDS) #procrustes
res1[1,2]<-cbind(ODSQ2cor$estimate)
res1[1,3]<-cbind(ODSQ2procrustes$t0)
} #end else #2
} #end else #1
}
#####################################
return(res1)
}#end function CoCalc
################################################################
#application of the function COP at different all dataset-based cutoffs
if(Type=="ADS"){
ecol.ext.all<-function(MM,Type,corcoef){
allcorr<-function(ODS,Type,corcoef){
ADS_perc<-c(0.01,seq(0.05,0.95,by=0.05),0.99)
table_taxa<-matrix(NA,length(ADS_perc),3)
row.names(table_taxa)<-ADS_perc
colnames(table_taxa)<-c("Sum","corrcoeff","R Procrustes")
for(i in 1:length(ADS_perc)){
table_taxa[((length(ADS_perc)+1)-i),]<-CoCalc(ODS,z=as.numeric(ADS_perc[i]),Type,corcoef)
}
#ROW<-row.names(table_taxa)
#table_taxa<-table_taxa[order(as.numeric(row.names(table_taxa)),decreasing=TRUE),]
#row.names(table_taxa)<-ROW
return(table_taxa)
} #end allcorr
list.ecol<-vector("list",length(MM))
names(list.ecol)<-names(MM)
for(j in 1:length(MM)){
list.ecol[[j]]<-allcorr(MM[[j]],Type,corcoef)
}
return(list.ecol)
} #end ecol.ext.all
}#end if "ADS"
#application of the function COP at different sample-based cutoffs
if(Type=="SAM"){
ecol.ext.all<-function(MM,Type,corcoef){
limSAMco=as.numeric(readline("\nIf SAM-based only, maximum cutoff value? (e.g. 208)...\t"))
allcorr<-function(ODS,Type,corcoef){
SAM_perc<-limSAMco*c(0.005,0.01,0.015,0.025,0.05,0.075,0.1,0.15,0.25,0.4,0.5,0.6,0.75,0.85,1)
table_taxa<-matrix(NA,length(SAM_perc),3)
row.names(table_taxa)<-round(SAM_perc,0)
colnames(table_taxa)<-c("Sum","corrcoeff","R Procrustes")
for(i in 1:length(SAM_perc)){
table_taxa[i,]<-CoCalc(ODS,z=as.numeric(SAM_perc[i]),Type,corcoef)
}
return(table_taxa)
} #end allcorr
list.ecol<-vector("list",length(MM))
names(list.ecol)<-names(MM)
for(j in 1:length(MM)){
list.ecol[[j]]<-allcorr(MM[[j]],Type,corcoef)
}
return(list.ecol)
} #end ecol.ext.all
}#end if "SAM"
result.allcorr<-ecol.ext.all(MM,Type,corcoef)
return(result.allcorr)
} #end cutoff.impact
###################################################################################
impct <- cutoff.impact(MM=tabs,details="y")
impct
plot(row.names(impct[[1]]),impct[[1]][,1],type="l",xlab=c("%cutoff removed"),ylab=c("Abundance in each matrix"))
impct[[1]]
impct[[1]][,1]
plot(row.names(impct[[3]]),impct[[3]][,3],type="l",xlab=c("%cutoff removed"),ylab=c("Abundance in each matrix"))
row.names(impct[[3]])
impct[[3]][,3]
plot(row.names(impct[[3]]),impct[[3]][,3])
par(mfrow=c(3,1))
plot(row.names(impct[[3]]),impct[[3]][,3])
df <- data.frame(names=row.names(impct[[3]]), values=impct[[3]][,3])
df
list.all<-vector("list",3)
names(list.all)<-c("Abundance","Non-par.correlation","Procrustes")
M <- impct
list.all[[1]]<-matrix(NA,nrow(M[[1]]),length(M))
list.all[[2]]<-matrix(NA,nrow(M[[1]]),length(M))
list.all[[3]]<-matrix(NA,nrow(M[[1]]),length(M))
colnames(list.all[[1]])<-names(M)
colnames(list.all[[2]])<-names(M)
colnames(list.all[[3]])<-names(M)
row.names(list.all[[1]])<-row.names(M[[1]])
row.names(list.all[[2]])<-row.names(M[[1]])
row.names(list.all[[3]])<-row.names(M[[1]])
df <- data.frame(names=row.names(impct[[3]]), values=impct[[3]][,3])
df
for(i in 1:length(M)){
list.all[[1]][,i]<-cbind(M[[i]][,1])
list.all[[2]][,i]<-cbind(M[[i]][,2])
list.all[[3]][,i]<-cbind(M[[i]][,3])
} #end for
list.all
plot(row.names(list.all[[1]]),list.all[[1]][,1],type="l",xlab=c("%cutoff removed"),ylab=c("Abundance in each matrix"))
df <- data.frame(names=row.names(impct[[3]]), values=impct[[3]][,3])
df
df.1 <- data.frame(names=row.names(impct[[3]]), values=impct[[3]][,3])
df.1 <- data.frame(names=row.names(impct[[1]]), values=impct[[1]][,1])
df.2 <- data.frame(names=row.names(impct[[2]]), values=impct[[2]][,1])
df.2
df.1
df.1 <- data.frame(names=row.names(impct[[1]]), values=impct[[1]][,1])
df.2 <- data.frame(names=row.names(impct[[2]]), values=impct[[2]][,1])
df.3 <- data.frame(names=row.names(impct[[3]]), values=impct[[3]][,1])
df.4 <-cbind(df.1,df.2,df.3)
df.4
df.1 <- cbind(df.1,c(impct[[2]][,1], impct[[3]][,1])
df.1 <- data.frame(cutoff=row.names(impct[[1]]), Abundance=impct[[1]][,1])
df.1 <- data.frame(cutoff=row.names(impct[[1]]), Abundance=impct[[1]][,1])
df.1 <- cbind(df.1,c(impct[[2]][,1], impct[[3]][,1]))
df.1 <- data.frame(cutoff=row.names(impct[[1]]), Abundance=impct[[1]][,1])
df.2 <- data.frame(cutoff=row.names(impct[[2]]), par.correlation=impct[[2]][,1])
df.3 <- data.frame(cutoff=row.names(impct[[3]]), Procrustes=impct[[3]][,1])
df.4 <-cbind(df.1,df.2,df.3)
df.4
str(impct[[2]][,1])
str(df.4)
df.4.m <- reshape2::melt(df.4)
df.4.m
ggplot(df.4.m, aes(cutoff, value)) + geom_line(aes(color=variable))
ggplot(df.4.m[,-c(1:2)], aes(cutoff, value)) + geom_line(aes(color=variable))
df.4.m[,-c(1:2)]
ggplot(df.4.m[,-c(1:2)], aes(cutoff, value)) + geom_path(aes(color=variable))
ggplot(df.4.m[,-c(1:2)], aes(cutoff, value)) + geom_point(aes(color=variable))
ggplot(df.4.m[,-c(1:2)], aes(as.numeric(cutoff), value)) + geom_point(aes(color=variable))
ggplot(df.4.m[,-c(1:2)], aes(as.numeric(cutoff), value)) +
geom_line(aes(color=variable))
ggplot(df.4.m[,-c(1:2)], aes(as.numeric(cutoff), value)) +
geom_line(aes(color=variable)) +
theme_bw()
df.1 <- data.frame(cutoff=row.names(impct[[1]]), Abundance=impct[[1]][,1])
df.2 <- data.frame(cutoff=row.names(impct[[2]]), par.correlation=impct[[2]][,2])
df.3 <- data.frame(cutoff=row.names(impct[[3]]), Procrustes=impct[[3]][,3])
df.4 <-cbind(df.1,df.2,df.3)
df.4
#make sure that no empty columns are present
#not run: which(apply(D,2,sum)==0) #to find empty columns. if you obtain "named integer(0)", then there is no empty column.
genus_tab <- tabs[[6]]
head(genus_tab)
N.OTU=ncol(D)
N.OTU
D=genus_tab
N.OTU=ncol(D) # Nber of OTUS in the whole dataset
N.OTU
SSOabs.D=  D[,apply(D,2,sum)==1]
SSOabs.N=  ncol(SSOabs.D) # Nber of SSOabs
SSOabs.pc=round(SSOabs.N/N.OTU,2) # proportion of SSOabs for the whole dataset
#producing a nice output
SSOabsPerSample=matrix(NA,nrow(D),2)
rownames(SSOabsPerSample)=rownames(D)
colnames(SSOabsPerSample)=c("Nb_SSOabs","PercentSSOabsToAllOTUs")
SSOabsPerSample[,1]=apply(SSOabs.D,1,sum)
SSOabsPerSample[,2]=matrix(round(SSOabsPerSample[,1]/N.OTU,2),nrow(D),1)
SSOabsPerSample #now contains a list of samples with 2 columns: 1) Nber of SSOabs per sample, 2) the corresponding proportion per sample
D1=D[,-(which(apply(D,2,sum)==1))] #removing SSOabs
SSOrel.D=D1[,which(apply(D1,2,function(x) any(x==1))==TRUE)]# SSOrel should have at least a sample with one sequence alone. See definition.
#SSOrel.D contains the subtable with all SSOrel of the dataset
SSOrel.N=ncol(SSOrel.D)#Nber of SSOrel in the whole dataset
SSOrel.N
#make sure that no empty columns are present
#not run: which(apply(D,2,sum)==0) #to find empty columns. if you obtain "named integer(0)", then there is no empty column.
genus_tab <- tabs[[7]]
D=genus_tab
N.OTU=ncol(D) # Nber of OTUS in the whole dataset
SSOabs.D=  D[,apply(D,2,sum)==1]
SSOabs.N=  ncol(SSOabs.D) # Nber of SSOabs
SSOabs.pc=round(SSOabs.N/N.OTU,2) # proportion of SSOabs for the whole dataset
#producing a nice output
SSOabsPerSample=matrix(NA,nrow(D),2)
rownames(SSOabsPerSample)=rownames(D)
colnames(SSOabsPerSample)=c("Nb_SSOabs","PercentSSOabsToAllOTUs")
SSOabsPerSample[,1]=apply(SSOabs.D,1,sum)
SSOabsPerSample[,2]=matrix(round(SSOabsPerSample[,1]/N.OTU,2),nrow(D),1)
SSOabsPerSample #now contains a list of samples with 2 columns: 1) Nber of SSOabs per sample, 2) the corresponding proportion per sample
N.OTU
D1=D[,-(which(apply(D,2,sum)==1))] #removing SSOabs
SSOrel.D=D1[,which(apply(D1,2,function(x) any(x==1))==TRUE)]# SSOrel should have at least a sample with one sequence alone. See definition.
#SSOrel.D contains the subtable with all SSOrel of the dataset
SSOrel.N=ncol(SSOrel.D)#Nber of SSOrel in the whole dataset
SSOrel.N
SSOabsPerSample
SubSampleNGS=function(Data,n,sub){
output=list(nOTU=matrix(NA,n,ncol(Data)),
chao1=matrix(NA,n,ncol(Data)),
ace=matrix(NA,n,ncol(Data)),
invS=matrix(NA,n,ncol(Data)),
shannon=matrix(NA,n,ncol(Data)),
SSOabs=matrix(NA,n,ncol(Data)),
SSOrel=matrix(NA,n,ncol(Data)),
DSOabs=matrix(NA,n,ncol(Data)))
colnames(output$nOTU)=colnames(output$chao1)=colnames(output$invS)=colnames(output$shannon)=
colnames(output$SSOabs)=colnames(output$SSOrel)=colnames(output$DSOabs)=colnames(Data)
for(j in 1:n){
#subsampling
x_sub=list()
for(i in 1:ncol(Data)){
sub1=rep(rownames(Data),Data[,i])
sub2=sample(sub1,size=sub)
x_sub[[i]]=data.frame(table(sub2))
colnames(x_sub[[i]])=c("ref.otu","abund")
}
SampleOTU=matrix(NA,nrow(Data),length(x_sub))
colnames(SampleOTU)=colnames(Data)
rownames(SampleOTU)=rownames(Data)
for (i in 1:length(x_sub)){
ref.otu=as.character(x_sub[[i]][,1])
SampleOTU[ref.otu,i]=x_sub[[i]][,2]
}
SampleOTU=SampleOTU[order(rownames(SampleOTU)),]
SampleOTU[is.na(SampleOTU)]<-0
head(SampleOTU)
tail(SampleOTU)
#exclude empty OTUs
Data_new=SampleOTU[!apply(SampleOTU,1,sum)==0,]
#nOTU
Data01=Data_new
Data01[Data01>0]<-1
nOTU=apply(Data01,2,sum)
output$nOTU[j,]=nOTU
#chao1 + ACE
chao1=estimateR(t(Data_new))
output$chao1[j,]=chao1[2,]
output$ace[j,]=chao1[4,]
#invS + shannon
invS=diversity(t(Data_new), "inv")
output$invS[j,]=invS
Shannon=diversity(t(Data_new), "shannon")
output$shannon[j,]=Shannon
#SSO
D=t(Data_new)  #represents a typical sample-by-OTU table
SSOabs.D=  D[,apply(D,2,sum)==1]
SSOabsPerSample=apply(SSOabs.D,1,sum)
output$SSOabs[j,]=round((SSOabsPerSample/nOTU)*100,2)
#DSOabs
DSOabs.D=  D[,apply(D,2,sum)==2]
DSOabsPerSample=apply(DSOabs.D,1,sum)
output$DSOabs[j,]=round((DSOabsPerSample/nOTU)*100,2)
#SSOrel
D1=D[,-(which(apply(D,2,sum)==1))] #removing SSOabs
SSOrel.D=D1[,which(apply(D1,2,function(x) any(x==1))==TRUE)]# SSOrel should have at least a sample with one sequence alone. See definition.
#SSOrel.D contains the subtable with all SSOrel of the dataset
SSOrel.N=ncol(SSOrel.D)#Nber of SSOrel in the whole dataset
SSOrelPerSample=apply(SSOrel.D,1,function(x) sum(x==1))
output$SSOrel[j,]=matrix(round((SSOrelPerSample/nOTU)*100,2),nrow(D),1)
}
return(output)
}
head(D)
# sub - library size (how many sequences per sample)
#
# output:
# list with values (number of OTU, chao1, inverse Simpson, absolute and relative singletons, absolute doubletons)
#  for each iteration
#
# dependencies:
#  require(vegan)
#=============================================================================
#documentation end
SubSampleNGS(t(D), 5, 1000)
output[[4]]
# sub - library size (how many sequences per sample)
#
# output:
# list with values (number of OTU, chao1, inverse Simpson, absolute and relative singletons, absolute doubletons)
#  for each iteration
#
# dependencies:
#  require(vegan)
#=============================================================================
#documentation end
xc <- SubSampleNGS(t(D), 5, 1000)
head(xc)
